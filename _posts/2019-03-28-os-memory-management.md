---
layout: post
title:  "操作系统内存管理学习笔记"
date:   2019-03-22
excerpt:  "本文是笔者学习操作系统内存管理的笔记"
tag:
- OS
comments: true
---

> 本文笔者总结操作系统层面是如何进行内存管理的，不涉及具体的实现算法，只介绍基本原理。

内存是计算机中最重要的资源之一，而且内存的容量是有限的，同时计算机中的应用程序的数量很大，所以为了高效的利用内存，操作系统必须以一定的方式对内存进行管理。

## 存储结构

计算机存储是有一个层次的，如下图所示:

![os_memory_management_1]({{site.url}}/assets/images/blog/os_memory_management_1.png)

越往上存储容量越小，读写速度越快，价格越高。

所以内存管理的目的就是协调和利用好这些不同的存储空间，以提高系统的执行效率。

## 进程介绍

这里简单介绍下进程相关概念，具体可以参考[这里](http://www.longjianjiang.com/process/)。

进程是操作系统中占有资源的最小单位，进程由程序，数据，进程控制块(PCB)三部分组成。所谓PCB就是用来记录进程的一些关键信息，比如进程标识符，程序和数据的内存地址等信息，这样操作系统就可以直接访问PCB去获取这些信息从而调度进程。

当计算机中的一个应用程序运行，首先需要将程序和数据装入内存，从而产生一个进程。

## 内存抽象

因为操作系统同一时间可能运行多个进程，所以不能直接操作内存地址，因为如果多个进程操作同一个内存地址可能导致错误。为此引入了地址空间的概念，这就允许每个进程有属于自己的地址。这需要CPU中有两个寄存器，一个是基址寄存器用来保存进程的起始地址，界址寄存器用来保存上限，防止内存溢出。

所以此时进程中访问内存地址是通过基址加上偏移量计算出实际的物理地址，因为每个进程的地址是不同的，所以此时也就不会出现多个进程操作同一块内存的可能，避免了错误的发生。

因为计算机中的应用程序很多，如果同时运行，内存大小就会存在不足，**交换技术**就是解决这个问题的。交换的原则其实很简单，将闲置的进程交换出内存，暂存到磁盘中，等到需要执行的时候再交换回内存。

> 下面就是如何给应用程序分配内存的几种不同的方式。

## 连续存储

所谓连续存储就是为应用程序分配一段连续的内存空间，这很好理解。连续存储有两种不同的实现方式:

### 单一连续存储

这种方式最简单，不过只适用于单用户单任务的操作系统。此时内存分为系统区和用户区，系统区只能供操作系统使用，余下的内存空间就是用户区，有时也会额外留出一部分给驱动程序使用。

### 分区存储

为了支持多道程序系统，引入了分区存储。所谓多道程序系统就是内存中可以存放多个应用程序，他们都处于运行中，这样可以提高CPU的使用率。

分区存储即是将内存划分为若干的相等或者不相等的分区，操作系统会占用其中一个分区，剩下的分区给应用程序使用，每个应用程序可能会占用一个或多个分区。

#### 固定分区

所谓固定分区即将内存划分为若干个固定大小的区域。

这些分区可以大小相等，此时适合多个相同的应用程序并发执行；分区大小也可以不想等，此时有多种不同大小的size，根据应用程序的大小分配合适的分区即可。

此时一般会维护一张分区使用表，记录了各个分区的起始地址，分区大小，以及是否分配状态。当应用程序要加载进内存时，内存分配程序会查该表找到一个合适的分区，用于分配给应用程序，同时更新分配状态，如果没有找到合适的分区则拒绝分配内存。

![os_memory_management_2]({{site.url}}/assets/images/blog/os_memory_management_2.png)

固定分区的优点是实现简单，缺点在于可能产生内碎片，因为分区的大小是固定的，导致可能应用程序只占用了分区的一部分内存，从而导致了内存的浪费；同时分区总数是固定的，从而限制了并发执行的数目。

#### 动态分区

所谓动态分区就是根据应用程序要求的内存创建分区，同时允许在执行过程中动态调整分区大小。

动态分区分配其实就是从内存中寻找一个空闲分区，该分区大小需要大于等于应用程序大小，如果大于应用程序大小，此时该分区会被分割为两部分，一部分就是应用程序大小的分区将其标记为占用，剩下的则被标记为空闲。分区释放的时候需要将相邻的空闲分区合并成一个大的空闲分区。

下面给出几种常见的分区分配算法:

> 动态分区可以使用双向链表来存储各个分区，链表中的节点存储了分区的信息。

- 首次适配法(first fit)

从链表头节点开始查找，找到第一个符合要求的分区后进行分配，若没有找到则分配失败。

该算法的优点每次从低地址寻找，可以将较大的空闲分区保留在高地址。缺点在于低地址部分随着不断的划分，会产生很多难以利用的小分区，又因为每次从低地址开始查找，额外增加了查找时间。

- 下次适配法(next fit)

该算法需要一个额外的指针标记上次分配的空闲分区的下一个空闲分区，查找时从这个指针位置开始查找，如果到尾部还没有找到则去头部进行继续查找，直到找到一个符合要求的分区将其分配，找到后更新指针。

该算法的优点在于使空闲分区分布的更加均匀，缺点在于不容易保留大的空闲分区。

- 最佳适配法(best fit)

该算法会在所有空闲分区按容量从小到大的顺序形成的一个空闲链表中中找到一个最小的满足条件的分区将其分配。

该算法的优点在于可以保留住大的空闲分区，并且从单个应用程序的角度来看，外碎片较小，缺点在于从因为最佳的缘故每次剩余的空闲分区是很小的，所以从整体来看形成来较多的外碎片。

- 最坏适配法(worst fit)

该算法会在所有空闲分区按容量从大到小的顺序形成的一个空闲链表中寻找，只要第一个满足要求将其分配即可。

该算法的优点在于不容易形成外碎片，因为留下的空闲分区不会太小，缺点在于难以保留大的空闲分区。

```
最坏适配法和之前所说的三种算法一起，也被称为顺序搜索法。
```

- 快速适配法(quick fit)

也被称为分类适配法，将空闲分区按大小进行分类，建立若干个空闲分区链表。所以寻找空闲分区只需要去合适大小的空闲分区链表中取第一个分配即可。

该算法的优点在于进行空闲分区分配时，不会产生分割，所以可以保留大的空闲分区，缺点在于实现复杂，系统开销比较大。

总的来说动态分区的优点在于没有内碎片，但是却引入了外碎片。

#### 伙伴系统

固定分区和动态分区都有缺点，所以有了伙伴系统。伙伴系统规定所有分区的大小都是2的k次幂(1<=k<=m)，所以2^1表示最小分区，2^m表示最大分区。

系统开始时，整个内存是2^m的空闲分区，随着系统的运行，会产生若干个不连续的空闲分区，将这些空闲分区按大小进行分类，建立若干个空闲分区双向链表。

此时为一个新的应用程序分配大小为n的存储空间的步骤如下:

1.根据`2^(i－1) <n ≤ 2^i`公式，计算出一个合适的空闲分区大小i，去空闲分区大小为2^i的链表中寻找；

2.如果找到，将其分配。

3.如果没有找到，则去空闲分区大小为2^(i+1)的链表中寻找，如果找到，将该分区分成两个2^i大小的分区，此时这两个分区称为一个伙伴，其中一个负责分配，另一个则加入空闲分区大小为2^i的链表中。

4.如果2^(i+1)的链表也没有找到，则去2^(i+2)的链表中寻找，此时首先将该分区分成两个2^(i+1)大小的分区，一个用户分配，另一个则加入空闲分区大小为2^(i+1)的链表中。将用于分配的2^(i+1)大小的分区分成两个2^i大小的分区，其中一个负责分配，另一个则加入空闲分区大小为2^i的链表中。

5.若还没有找到，则2^(i+3)的链表中寻找，找到后按同样的方法进行分割即可。

所以当将分区进行回收的时候，也可能有多次合并的过程。如回收大小为2^i的空闲分区时，若事先已存在2^i的空闲分区时，则应将其合并为大小为2^(i+1)的空闲分区，若事先已存在2^(i+1)的空闲分区时，继续将其合并为大小为2^(i+2)的空闲分区，依此类推。

### 内存紧凑(memory compaction)

所谓内存紧凑就是消除内存碎片的，将占用的分区往内存的一端移动，从而可以产生一个大的空闲分区，不过移动已占用的内存非常消耗CPU资源。

但是将占用的分区移动后，此时应用程序的地址就需要更新，否则就无法运行。不过更新也很简单，因为程序在装入内存中都是相对地址，等到执行的时候才会映射到物理地址，而映射就是之前所说的使用基址加上相对地址，所以这里紧凑后只需要用应用程序新的起始地址更新基址寄存器即可。

进行内存紧凑的时机有两种，一种是当分区释放后立即内存紧凑，另一种当内存分配找不到合适的空闲分区时进行内存紧凑。

## 覆盖

之前说到了内存抽象满足了多进程的要求，但是如果某个进程的大小比内存还要大(例如游戏)，**覆盖技术**是一种解决这种问题的方法。

所谓覆盖计数就是将程序分为多个块，首先将必要部分的块加载到内存，可选部分在需要时依次加载到内存中。这个方案的最大问题在于要求程序员去给程序进行分块，这是一个复杂耗时的操作，增加了编程的复杂度。

## 虚拟内存

之前的内存分配方式分配的都是一块连续的内存，使用的地址都是物理地址。如果允许分配的内存不连续，这样就可以减少内存碎片同时不需要进行内存紧凑操作。

同时上述所说的内存分配都是需要将进程全部装入内存后才能运行，但很多时候进程运行的时候并非所有的程序和数据都会用到，有些程序可能只运行一次以后就再也不会被运行了，但是却依然存放在容量有限的内存中，造成了内存的浪费。

```
局部性原理: 在一较短的时间内，程序的执行仅局限于某个部分，相应的，它所访问的存储空间也局限于某个区域。

时间局限性: 程序的某条指令一旦被执行，接下来则会有较大可能继续被执行；内存中某个数据被访问，接下来则会有较大可能继续被访问。

空间局限性: 某个内存单元被访问，接下来附近的内存会有较大可能被方法。
```

综上，虚拟内存应运而生，同时这也是**覆盖技术**的替换方案。此时应用程序的执行，不必全部加载进内存，而是以一种按需加载的方式加载。

虚拟内存中，每个进程拥有独立的逻辑地址空间，此时内存按照分配单位的不同，分为页式存储和段式存储，两者被称为离散分配。

## 页式存储

应用程序的逻辑地址划分为多个固定大小的页，每个页都是一段连续的地址。此时对于进程来说，逻辑上有很多内存空间，但是其中一部分对应到物理内存(称为页框，大小和页相等)，而一些未加载的则对应在磁盘上。由此可知，虚拟内存比物理内存要大。

页面大小的划分一般是2的幂，大小需要适中，太小导致页表过长，降低页面换进换出的效率，太大则导致页内碎片过大。一般页面大小为512B~8KB。

页式存储的逻辑地址结构如下所示:

![os_memory_management_3]({{site.url}}/assets/images/blog/os_memory_management_3.png)

可以看到由两部分组成，前部分是页号，后部分是偏移量也即是页内地址。上图地址长度32位，0-11位是页内地址，每页大小为4KB；12-31位是页号，地址空间最多包含1M页。

因为离散分配的缘故，所以操作系统会为进程创建一张页表，进行逻辑地址到物理内存的映射，如下图所示:

![os_memory_management_4]({{site.url}}/assets/images/blog/os_memory_management_4.png)

CPU中存在一个页表寄存器，用来存放页表的开始地址和页表的长度，应用程序的页表首先存放在内存中，当操作系统调度到某个进程时，才会将该进程页表的这两个数据存放到页表寄存器。

当访问到进程的某个逻辑地址的时候，就需要将逻辑地址进行转化为实际的物理地址，此时就需要使用到页表寄存器，这一过程由硬件完成。首先用逻辑地址中的页号和页表长度进行比对，如果大于等于页表长度，则表示本次需要访问的地址超过了进程的地址空间，从而产生地址越界中断。如果地址合法，则根据页表开始地址乘以页号和页表大小的结果得到该页在页表中的位置，从而可以得到对应的物理页框号，最后加上页内地址就完成了逻辑地址到物理地址的转化。过程如下图所示:

![os_memory_management_5]({{site.url}}/assets/images/blog/os_memory_management_5.png)

上述逻辑地址转化物理地址的过程，需要访问两次内存，第一次是访问内存中的页表，第二次则是对得到的物理地址进行读写操作。这种方式会降低计算机的执行速度，所以为了提高地址转化的速度，所以将页表放入CPU中的一个具有并行查找能力的高速缓冲寄存器，也称为快表。因为页表可能比较大，所以快表无法存放页表中所有的数据，所以需要一个更新操作，所以快表中存储的都是进程经常访问的地址。

有了快表之后的地址转换过程如下: 拿到逻辑地址后，直接将页号送入快表中，进行查找对应的物理页框号，如果找不到则去内存中的页表中查找，查找成功后将该页表的一行数据进行更新到快表中。当快表满了后，同样需要进行清理不经常使用的页表项。因为局部性原理，从快表中找到对应的物理页框号的概率可以达到90%以上。过程如下图所示:

![os_memory_management_6]({{site.url}}/assets/images/blog/os_memory_management_6.png)

计算机中可能支持比较大的逻辑地址空间，所以会导致页表会很大，从而需要一块较大的连续的内存空间去存储页表。此时一般会将页表进行分页，从而需要外层创建一个页表来指向这些分页的页表。下面以两级页表为例进行说明，此时逻辑地址表示和页表结构如下所示:

![os_memory_management_7]({{site.url}}/assets/images/blog/os_memory_management_7.png)
![os_memory_management_8]({{site.url}}/assets/images/blog/os_memory_management_8.png)

从上图可以看到，地址由三部分组成，进行地址转换的时候，首先根据外层页号找到指定页表的某一页，在根据外部页内地址，定位到页表中的项，从而得到物理地址，最后加上页内地址，完成地址转换操作。过程如下图所示:

![os_memory_management_9]({{site.url}}/assets/images/blog/os_memory_management_9.png)

现在让我们看另一个问题，之前说到页表中的某项可能指向的并不是实际的物理地址，而是磁盘地址，如果地址转换的时候定位到指向磁盘地址的表项时，会产生所谓的**缺页中断**。此时会从磁盘中取得所缺的页将其放入内存，如果此时内存已满，则需要从内存中选择某一页将其送到磁盘的交换区。

因为从磁盘中读数据的速度很慢，所以每次产生中断会很影响计算机的性能，所以进行页面置换就需要一定的算法来保证不将未来需要使用到的页置换出去，下面给出常见的页面置换算法:

- 最佳(Optimal)置换算法

该算法是一种理论上的算法，要求将未来最不久使用的算法置换出去。

- 先进先出(FIFO)算法

该算法选择将在内存中存放时间最长的页置换出，实现简单，因为局部性原理的存在，性能并不好。

该算法有个改进版本，给页增加一个标记，如果最近使用过将标记置为1，当页进行置换时，标记为1则不置换同时将标记置为0，继续寻找，找到标记为0的页则进行置换。

- 最近最久(Least Recently Used)未使用算法

该算法选择将内存中最近最长时间未使用的页置换出，实现复杂，性能较好。

- 时钟(Clock)算法

该算法在先进先出算法的基础上将队列相连形成一个环路，每次从当前位置寻找一个标记为0的页，所经过的页标记为1的页都置为0，当到最后一个页时则返回到第一页，直到找到。过程如下图所示:

![os_memory_management_10]({{site.url}}/assets/images/blog/os_memory_management_10.png)

## 段式存储

之前的分页是将内存进行划分，而分段则是将应用程序进行进行分段，内存分配的时候为这些不同的段进行分配连续的内存，而这些段之前则不必连续。一般程序会划分为代码段，数据段，共享段，栈段等等。

段式存储的逻辑地址结构如下所示:

![os_memory_management_11]({{site.url}}/assets/images/blog/os_memory_management_11.png)

可以看到由两部分组成，前部分是段号，后部分是偏移量也即是段内地址。上述地址结构允许最多有64K个段，每个段最大长度为64KB。

和页式存储一样，操作系统会为进程创建一张段表，进行逻辑地址到物理内存的映射，如下图所示:

![os_memory_management_12]({{site.url}}/assets/images/blog/os_memory_management_12.png)

和页式存储一样，CPU中会设置段表寄存器，存放段表的开始地址和段表的长度。进行地址转换的时候，首先用逻辑地址中的段号和段表长度进行比对，如果大于等于段表长度，则表示本次需要访问的地址超过了进程的地址空间，从而产生地址越界中断。如果地址合法，则根据段表开始地址乘以段号和段表大小的结果得到该段在段表中的位置，读出该段在内存中的开始地址，然后检查逻辑地址中的段内地址是否大于该段的长度，如果大于则产生地址越界中断。否则根据该段在内存中的开始地址加上段内地址即可完成转换。过程如下图所示:

![os_memory_management_13]({{site.url}}/assets/images/blog/os_memory_management_13.png)

和页式存储一样，因为两次访问内存的缘故，会增加快表。

因为段式存储是以信息的逻辑进行分组的，所以相同功能的段很容易的可以被共享。同时段式存储可以实现动态链接，程序运行过程中根据需要动态的将程序中的某个段加载进内存进行链接。

## 段页式存储

段页式存储则是页式和段式两种存储方式的结合版。即有页式的高效利用内存的优点，也有段式的方便共享，可动态链接的优点。

首先会将程序进行分段，然后将每个段划分为若干页，此时的逻辑地址结构如下所示:

![os_memory_management_14]({{site.url}}/assets/images/blog/os_memory_management_14.png)

此时的地址转换过程则结合了之前的两种方式，过程如下所示:

![os_memory_management_15]({{site.url}}/assets/images/blog/os_memory_management_15.png)

## 总结

本文将操作系统的内存管理进行了一个简单的总结。

## References

[计算机操作系统-汤小丹](https://book.douban.com/subject/26079463/)